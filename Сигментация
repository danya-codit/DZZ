import os
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import albumentations as A
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torch.optim as optim
from torchvision import transforms
import segmentation_models_pytorch as smp
from tqdm import tqdm
# 1. Подключение Google Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# 2. Конфигурация путей
DATA_ROOT = '/content/drive/MyDrive/Цифровая кафедра/Сигментация/Полный архив'
CLASSES = {
    'Лес': [0, 255, 0],    # Зеленый
    'Поле': [255, 255, 0], # Желтый
    'Город': [255, 0, 0],  # Красный
    'Вода': [0, 0, 255]    # Синий
}
# 3. Проверка структуры данных
print("Содержимое рабочей папки:")
!ls -la "{DATA_ROOT}"

print("\nКоличество файлов в каждой папке:")
for class_name in CLASSES.keys():
    class_path = os.path.join(DATA_ROOT, class_name)
    if os.path.exists(class_path):
        count = len(os.listdir(class_path))
        print(f"{class_name}: {count} файлов")
    else:
        print(f"⚠️ Папка {class_name} не найдена")

# 4. Функция для чтения изображений с обработкой ошибок
def read_image(path):
    try:
        # Пробуем прочитать как TIFF
        if path.lower().endswith(('.tif', '.tiff')):
            try:
                return tifffile.imread(path)
            except:
                return np.array(Image.open(path))
        else:
            return np.array(Image.open(path))
    except Exception as e:
        print(f"Ошибка чтения {path}: {str(e)}")
        return None

# 5. Класс Dataset для работы напрямую с исходными файлами
class SatelliteDataset(Dataset):
    def __init__(self, root_dir, classes, transform=None, mode='train'):
        self.samples = []
        self.transform = transform

        for class_name, color in classes.items():
            class_dir = os.path.join(root_dir, class_name)
            if not os.path.exists(class_dir):
                continue

            files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.tif', '.tiff', '.png', '.jpg', '.jpeg'))]
            train_files, val_files = train_test_split(files, test_size=0.2, random_state=42)

            for f in (train_files if mode == 'train' else val_files):
                self.samples.append((
                    os.path.join(class_dir, f),
                    color
                ))

        if not self.samples:
            raise ValueError(f"Не найдено изображений для {mode}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, color = self.samples[idx]

        img = read_image(img_path)
        if img is None:
            return self.__getitem__((idx + 1) % len(self))

        # Нормализация
        if img.dtype == np.uint16:
            img = (img / 256).astype(np.uint8)
        if len(img.shape) == 2:
            img = np.stack([img]*3, axis=-1)
        img = img[:,:,:3]

        # Создание маски
        mask = np.zeros_like(img)
        mask[:] = color

        if self.transform:
            augmented = self.transform(image=img, mask=mask)
            img, mask = augmented['image'], augmented['mask']

        return transforms.ToTensor()(img), transforms.ToTensor()(mask)

# 6. Безопасные аугментации для изображений 100x100
train_transform = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomRotate90(p=0.5),
    A.RandomBrightnessContrast(
        brightness_limit=0.1, 
        contrast_limit=0.1, 
        p=0.5
    ),
    # Убраны ВСЕ операции обрезки (Crop)
    # Добавлено только масштабирование при необходимости
    A.Resize(100, 100, always_apply=True)  # Гарантируем размер 100x100
])

val_transform = A.Compose([
    A.Resize(100, 100, always_apply=True)  # Только ресайз для валидации
])


# 7. Исправленный класс Dataset с безопасной обработкой изображений
class SatelliteDataset(Dataset):
    def __init__(self, root_dir, classes, transform=None, mode='train'):
        self.samples = []
        self.transform = transform
        
        # Собираем все доступные изображения
        for class_name, color in classes.items():
            class_dir = os.path.join(root_dir, class_name)
            if not os.path.exists(class_dir):
                print(f"⚠️ Папка {class_name} не найдена, пропускаем")
                continue
                
            # Получаем все поддерживаемые изображения
            valid_extensions = ('.tif', '.tiff', '.png', '.jpg', '.jpeg')
            files = [f for f in os.listdir(class_dir) 
                    if f.lower().endswith(valid_extensions)]
            
            if not files:
                print(f"⚠️ В папке {class_name} нет подходящих изображений")
                continue
                
            # Разделение на train/val
            train_files, val_files = train_test_split(files, test_size=0.2, random_state=42)
            
            for f in (train_files if mode == 'train' else val_files):
                self.samples.append((
                    os.path.join(class_dir, f),
                    color
                ))
        
        if not self.samples:
            raise ValueError(f"Не найдено изображений для {mode}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, color = self.samples[idx]
        
        try:
            # Чтение с обработкой ошибок
            img = read_image(img_path)
            if img is None:
                raise ValueError(f"Не удалось прочитать {img_path}")
                
            # Нормализация
            if img.dtype == np.uint16:
                img = (img / 256).astype(np.uint8)
            if len(img.shape) == 2:
                img = np.stack([img]*3, axis=-1)
            img = img[:,:,:3]
            
            # Гарантированный ресайз
            if img.shape[0] != 100 or img.shape[1] != 100:
                img = cv2.resize(img, (100, 100), interpolation=cv2.INTER_AREA)
            
            # Создание маски
            mask = np.zeros_like(img)
            mask[:] = color
            
            # Безопасное применение аугментаций
            if self.transform:
                try:
                    augmented = self.transform(image=img, mask=mask)
                    img, mask = augmented['image'], augmented['mask']
                except Exception as e:
                    print(f"⚠️ Ошибка аугментации (файл: {os.path.basename(img_path)}): {str(e)}")
                    # Возвращаем оригиналы если аугментация не удалась
            
            return transforms.ToTensor()(img), transforms.ToTensor()(mask)
            
        except Exception as e:
            print(f"⚠️ Критическая ошибка (файл: {os.path.basename(img_path)}): {str(e)}")
            # Возвращаем нули если совсем ничего не работает
            dummy_img = torch.zeros(3, 100, 100)
            dummy_mask = torch.zeros(3, 100, 100)
            return dummy_img, dummy_mask
# 8. Улучшенная функция визуализации со случайной выборкой
def show_samples(dataset, title, num_samples=3, random_seed=None):
    """
    Визуализирует случайные примеры из датасета
    
    Параметры:
        dataset: Датасет для визуализации
        title: Заголовок для отображения
        num_samples: Количество примеров (по умолчанию 3)
        random_seed: Фиксированный seed для воспроизводимости (None для случайных)
    """
    plt.figure(figsize=(10, 5))
    
    # Создаем временный датасет без аугментаций
    from copy import deepcopy
    vis_dataset = deepcopy(dataset)
    vis_dataset.transform = None  # Отключаем аугментации
    
    # Проверяем доступное количество примеров
    num_samples = min(num_samples, len(vis_dataset))
    if num_samples <= 0:
        print("⚠️ Нет доступных примеров для визуализации")
        return
    
    # Выбираем случайные индексы
    if random_seed is not None:
        np.random.seed(random_seed)
    random_indices = np.random.choice(len(vis_dataset), num_samples, replace=False)
    
    for i, idx in enumerate(random_indices):
        try:
            img, mask = vis_dataset[idx]
            
            # Визуализация изображения
            plt.subplot(2, num_samples, i+1)
            plt.imshow(img.permute(1, 2, 0))
            plt.title(f"{title} {i+1}\n{os.path.basename(dataset.samples[idx][0])}")
            plt.axis('off')
            
            # Визуализация маски
            plt.subplot(2, num_samples, i+1+num_samples)
            plt.imshow(mask.permute(1, 2, 0))
            plt.title(f"Маска {i+1}")
            plt.axis('off')
            
        except Exception as e:
            print(f"Ошибка визуализации примера {idx}: {str(e)}")
            continue
    
    plt.tight_layout()
    plt.show()
    plt.close()  # Закрываем фигуру чтобы не накапливались в памяти

kol=5
print("\n5 случайных примеров:")
show_samples(train_dataset, "Train", num_samples=kol)
print("\n5 случайных примеров:")
show_samples(val_dataset, "Validation", num_samples=kol)
