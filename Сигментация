import os
import cv2
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import albumentations as A
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
import torch.optim as optim
from torchvision import transforms
import segmentation_models_pytorch as smp
from tqdm import tqdm
# 1. Подключение Google Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# 2. Конфигурация путей
DATA_ROOT = '/content/drive/MyDrive/Цифровая кафедра/Сигментация/Полный архив'
CLASSES = {
    'Лес': [0, 255, 0],    # Зеленый
    'Поле': [255, 255, 0], # Желтый
    'Город': [255, 0, 0],  # Красный
    'Вода': [0, 0, 255]    # Синий
}
# 3. Проверка структуры данных
print("Содержимое рабочей папки:")
!ls -la "{DATA_ROOT}"

print("\nКоличество файлов в каждой папке:")
for class_name in CLASSES.keys():
    class_path = os.path.join(DATA_ROOT, class_name)
    if os.path.exists(class_path):
        count = len(os.listdir(class_path))
        print(f"{class_name}: {count} файлов")
    else:
        print(f"⚠️ Папка {class_name} не найдена")

# 4. Функция для чтения изображений с обработкой ошибок
def read_image(path):
    try:
        # Пробуем прочитать как TIFF
        if path.lower().endswith(('.tif', '.tiff')):
            try:
                return tifffile.imread(path)
            except:
                return np.array(Image.open(path))
        else:
            return np.array(Image.open(path))
    except Exception as e:
        print(f"Ошибка чтения {path}: {str(e)}")
        return None

# 5. Класс Dataset для работы напрямую с исходными файлами
class SatelliteDataset(Dataset):
    def __init__(self, root_dir, classes, transform=None, mode='train'):
        self.samples = []
        self.transform = transform

        for class_name, color in classes.items():
            class_dir = os.path.join(root_dir, class_name)
            if not os.path.exists(class_dir):
                continue

            files = [f for f in os.listdir(class_dir) if f.lower().endswith(('.tif', '.tiff', '.png', '.jpg', '.jpeg'))]
            train_files, val_files = train_test_split(files, test_size=0.2, random_state=42)

            for f in (train_files if mode == 'train' else val_files):
                self.samples.append((
                    os.path.join(class_dir, f),
                    color
                ))

        if not self.samples:
            raise ValueError(f"Не найдено изображений для {mode}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, color = self.samples[idx]

        img = read_image(img_path)
        if img is None:
            return self.__getitem__((idx + 1) % len(self))

        # Нормализация
        if img.dtype == np.uint16:
            img = (img / 256).astype(np.uint8)
        if len(img.shape) == 2:
            img = np.stack([img]*3, axis=-1)
        img = img[:,:,:3]

        # Создание маски
        mask = np.zeros_like(img)
        mask[:] = color

        if self.transform:
            augmented = self.transform(image=img, mask=mask)
            img, mask = augmented['image'], augmented['mask']

        return transforms.ToTensor()(img), transforms.ToTensor()(mask)

# 6. Безопасные аугментации для изображений 100x100
train_transform = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.RandomRotate90(p=0.5),
    A.RandomBrightnessContrast(
        brightness_limit=0.1, 
        contrast_limit=0.1, 
        p=0.5
    ),
    # Убраны ВСЕ операции обрезки (Crop)
    # Добавлено только масштабирование при необходимости
    A.Resize(100, 100, always_apply=True)  # Гарантируем размер 100x100
])

val_transform = A.Compose([
    A.Resize(100, 100, always_apply=True)  # Только ресайз для валидации
])


# 7. Исправленный класс Dataset с безопасной обработкой изображений
class SatelliteDataset(Dataset):
    def __init__(self, root_dir, classes, transform=None, mode='train'):
        self.samples = []
        self.transform = transform
        
        # Собираем все доступные изображения
        for class_name, color in classes.items():
            class_dir = os.path.join(root_dir, class_name)
            if not os.path.exists(class_dir):
                print(f"⚠️ Папка {class_name} не найдена, пропускаем")
                continue
                
            # Получаем все поддерживаемые изображения
            valid_extensions = ('.tif', '.tiff', '.png', '.jpg', '.jpeg')
            files = [f for f in os.listdir(class_dir) 
                    if f.lower().endswith(valid_extensions)]
            
            if not files:
                print(f"⚠️ В папке {class_name} нет подходящих изображений")
                continue
                
            # Разделение на train/val
            train_files, val_files = train_test_split(files, test_size=0.2, random_state=42)
            
            for f in (train_files if mode == 'train' else val_files):
                self.samples.append((
                    os.path.join(class_dir, f),
                    color
                ))
        
        if not self.samples:
            raise ValueError(f"Не найдено изображений для {mode}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, color = self.samples[idx]
        
        try:
            # Чтение с обработкой ошибок
            img = read_image(img_path)
            if img is None:
                raise ValueError(f"Не удалось прочитать {img_path}")
                
            # Нормализация
            if img.dtype == np.uint16:
                img = (img / 256).astype(np.uint8)
            if len(img.shape) == 2:
                img = np.stack([img]*3, axis=-1)
            img = img[:,:,:3]
            
            # Гарантированный ресайз
            if img.shape[0] != 100 or img.shape[1] != 100:
                img = cv2.resize(img, (100, 100), interpolation=cv2.INTER_AREA)
            
            # Создание маски
            mask = np.zeros_like(img)
            mask[:] = color
            
            # Безопасное применение аугментаций
            if self.transform:
                try:
                    augmented = self.transform(image=img, mask=mask)
                    img, mask = augmented['image'], augmented['mask']
                except Exception as e:
                    print(f"⚠️ Ошибка аугментации (файл: {os.path.basename(img_path)}): {str(e)}")
                    # Возвращаем оригиналы если аугментация не удалась
            
            return transforms.ToTensor()(img), transforms.ToTensor()(mask)
            
        except Exception as e:
            print(f"⚠️ Критическая ошибка (файл: {os.path.basename(img_path)}): {str(e)}")
            # Возвращаем нули если совсем ничего не работает
            dummy_img = torch.zeros(3, 100, 100)
            dummy_mask = torch.zeros(3, 100, 100)
            return dummy_img, dummy_mask
# 8. Улучшенная функция визуализации со случайной выборкой
def show_samples(dataset, title, num_samples=3, random_seed=None):
    """
    Визуализирует случайные примеры из датасета
    
    Параметры:
        dataset: Датасет для визуализации
        title: Заголовок для отображения
        num_samples: Количество примеров (по умолчанию 3)
        random_seed: Фиксированный seed для воспроизводимости (None для случайных)
    """
    plt.figure(figsize=(10, 5))
    
    # Создаем временный датасет без аугментаций
    from copy import deepcopy
    vis_dataset = deepcopy(dataset)
    vis_dataset.transform = None  # Отключаем аугментации
    
    # Проверяем доступное количество примеров
    num_samples = min(num_samples, len(vis_dataset))
    if num_samples <= 0:
        print("⚠️ Нет доступных примеров для визуализации")
        return
    
    # Выбираем случайные индексы
    if random_seed is not None:
        np.random.seed(random_seed)
    random_indices = np.random.choice(len(vis_dataset), num_samples, replace=False)
    
    for i, idx in enumerate(random_indices):
        try:
            img, mask = vis_dataset[idx]
            
            # Визуализация изображения
            plt.subplot(2, num_samples, i+1)
            plt.imshow(img.permute(1, 2, 0))
            plt.title(f"{title} {i+1}\n{os.path.basename(dataset.samples[idx][0])}")
            plt.axis('off')
            
            # Визуализация маски
            plt.subplot(2, num_samples, i+1+num_samples)
            plt.imshow(mask.permute(1, 2, 0))
            plt.title(f"Маска {i+1}")
            plt.axis('off')
            
        except Exception as e:
            print(f"Ошибка визуализации примера {idx}: {str(e)}")
            continue
    
    plt.tight_layout()
    plt.show()
    plt.close()  # Закрываем фигуру чтобы не накапливались в памяти

kol=5
print("\n5 случайных примеров:")
show_samples(train_dataset, "Train", num_samples=kol)
print("\n5 случайных примеров:")
show_samples(val_dataset, "Validation", num_samples=kol)

# 9. Обучение модели с визуализацией прогресса
def train_and_evaluate():
    # Создаем датасеты
    train_dataset = SatelliteDataset(DATA_ROOT, CLASSES, train_transform, 'train')
    val_dataset = SatelliteDataset(DATA_ROOT, CLASSES, val_transform, 'val')
    
    # Даталоадеры
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=8)
    
    # Инициализация модели
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = smp.Unet(
        'resnet34',
        encoder_weights='imagenet',
        classes=3,
        activation='sigmoid'
    ).to(device)
    
    # Оптимизатор и функция потерь
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.BCEWithLogitsLoss()
    
    # Для отслеживания метрик
    train_loss_history = []
    val_loss_history = []
    train_iou_history = []
    val_iou_history = []
    
    # Обучение
    num_epochs = 10
    best_val_loss = float('inf')
    
    for epoch in range(num_epochs):
        model.train()
        epoch_train_loss = 0.0
        epoch_train_iou = 0.0
        
        # Прогресс-бар для обучения
        train_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Train]')
        for images, masks in train_bar:
            images, masks = images.to(device), masks.to(device)
            
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, masks)
            loss.backward()
            optimizer.step()
            
            # Вычисляем IoU
            iou = smp.metrics.iou_score(outputs.sigmoid(), masks, threshold=0.5)
            
            epoch_train_loss += loss.item()
            epoch_train_iou += iou.item()
            
            train_bar.set_postfix({
                'loss': loss.item(),
                'iou': iou.item()
            })
        
        # Валидация
        model.eval()
        epoch_val_loss = 0.0
        epoch_val_iou = 0.0
        
        with torch.no_grad():
            val_bar = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [Val]')
            for images, masks in val_bar:
                images, masks = images.to(device), masks.to(device)
                outputs = model(images)
                
                loss = criterion(outputs, masks)
                iou = smp.metrics.iou_score(outputs.sigmoid(), masks, threshold=0.5)
                
                epoch_val_loss += loss.item()
                epoch_val_iou += iou.item()
                
                val_bar.set_postfix({
                    'loss': loss.item(),
                    'iou': iou.item()
                })
        
        # Сохраняем метрики
        train_loss_history.append(epoch_train_loss / len(train_loader))
        val_loss_history.append(epoch_val_loss / len(val_loader))
        train_iou_history.append(epoch_train_iou / len(train_loader))
        val_iou_history.append(epoch_val_iou / len(val_loader))
        
        # Сохраняем лучшую модель
        if epoch_val_loss < best_val_loss:
            best_val_loss = epoch_val_loss
            model_path = '/content/drive/MyDrive/Цифровая кафедра/Сигментация/best_model.pth'
            torch.save(model.state_dict(), model_path)
            print(f"\nSaved best model to {model_path}")
    
    # Визуализация метрик
    plt.figure(figsize=(12, 5))
    
    # График потерь
    plt.subplot(1, 2, 1)
    plt.plot(train_loss_history, label='Train Loss')
    plt.plot(val_loss_history, label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    
    # График IoU (Accuracy)
    plt.subplot(1, 2, 2)
    plt.plot(train_iou_history, label='Train IoU')
    plt.plot(val_iou_history, label='Validation IoU')
    plt.title('Training and Validation IoU')
    plt.xlabel('Epoch')
    plt.ylabel('IoU Score')
    plt.legend()
    
    plt.tight_layout()
    
    # Сохраняем графики
    plots_dir = '/content/drive/MyDrive/Цифровая кафедра/Сигментация/training_plots'
    os.makedirs(plots_dir, exist_ok=True)
    plt.savefig(os.path.join(plots_dir, 'training_metrics.png'))
    plt.show()
    plt.close()
    
    # Визуализация примеров после обучения
    visualize_predictions(model, val_dataset, device)

# 10. Функция для визуализации предсказаний
def visualize_predictions(model, dataset, device, num_samples=3):
    model.eval()
    indices = np.random.choice(len(dataset), num_samples)
    
    plt.figure(figsize=(15, 5 * num_samples))
    
    for i, idx in enumerate(indices):
        # Получаем данные
        image, true_mask = dataset[idx]
        image = image.unsqueeze(0).to(device)
        
        # Делаем предсказание
        with torch.no_grad():
            pred_mask = model(image).sigmoid().squeeze().cpu()
        
        # Преобразуем в numpy
        image_np = image.squeeze().cpu().permute(1, 2, 0).numpy()
        true_mask_np = true_mask.permute(1, 2, 0).numpy()
        pred_mask_np = (pred_mask > 0.5).float().permute(1, 2, 0).numpy()
        
        # Оригинальное изображение
        plt.subplot(num_samples, 3, i*3 + 1)
        plt.imshow(image_np)
        plt.title(f"Пример {i+1}\nОригинал")
        plt.axis('off')
        
        # Истинная маска
        plt.subplot(num_samples, 3, i*3 + 2)
        plt.imshow(true_mask_np)
        plt.title("Истинная маска")
        plt.axis('off')
        
        # Предсказанная маска
        plt.subplot(num_samples, 3, i*3 + 3)
        plt.imshow(pred_mask_np)
        plt.title("Предсказание")
        plt.axis('off')
    
    plt.tight_layout()
    
    # Сохраняем визуализацию
    preds_dir = '/content/drive/MyDrive/Цифровая кафедра/Сигментация/predictions'
    os.makedirs(preds_dir, exist_ok=True)
    plt.savefig(os.path.join(preds_dir, 'model_predictions.png'))
    plt.show()
    plt.close()

# Запуск обучения
if __name__ == "__main__":
    train_and_evaluate()
